{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b4cff6-4da6-4f78-a350-62e57d6bd339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090 D\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import deepxde as dde\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "import plotly.graph_objects as go # for plotting the graph\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd._functions import tensor\n",
    "from torch.utils import data\n",
    "from torch.utils.data import TensorDataset\n",
    "from scipy.signal import find_peaks\n",
    "from deepxde.data.data import Tuple\n",
    "from deepxde.nn import initializers\n",
    "from deepxde.nn.pytorch.nn import NN\n",
    "from deepxde.nn import activations\n",
    "from deepxde import config\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler  # 标准化工具\n",
    "from sklearn.metrics import mean_squared_error # 均方误差\n",
    "from deepxde.nn.pytorch.fnn import FNN\n",
    "from deepxde.nn.pytorch.nn import NN\n",
    "from deepxde.nn import activations\n",
    "from deepxde.data import Data\n",
    "from deepxde.data import BatchSampler\n",
    "from deepxde.nn.deeponet_strategy import (\n",
    "    SingleOutputStrategy,\n",
    "    IndependentStrategy,\n",
    "    SplitBothStrategy,\n",
    "    SplitBranchStrategy,\n",
    "    SplitTrunkStrategy,\n",
    ")\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# 'cuda' 这里如果没有指定具体的卡号,系统默认cuda:0\n",
    "device = torch.device('cuda:0') \t\t# 使用2号卡\n",
    "print(torch.cuda.get_device_name(0)) # 查看使用的设备名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c0218e-4eb3-41ba-a9d8-a837cf212af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DNN\n",
    "class FNN(NN):\n",
    "    \"\"\"Fully-connected neural network.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes, activation, kernel_initializer, regularization=None ):\n",
    "        super().__init__()\n",
    "        if isinstance(activation, list):\n",
    "            if not (len(layer_sizes) - 1) == len(activation):\n",
    "                raise ValueError(\n",
    "                    \"Total number of activation functions do not match with sum of hidden layers and output layer!\"\n",
    "                )\n",
    "            self.activation = list(map(activations.get, activation))\n",
    "        else:\n",
    "            self.activation = activations.get(activation)\n",
    "        initializer = initializers.get(kernel_initializer)\n",
    "        initializer_zero = initializers.get(\"zeros\")    \n",
    "        self.regularizer = regularization  # =None\n",
    "\n",
    "        self.linears = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.linears.append(\n",
    "                torch.nn.Linear(\n",
    "                    layer_sizes[i - 1], layer_sizes[i], dtype=config.real(torch)\n",
    "                )\n",
    "            )\n",
    "            initializer(self.linears[-1].weight)\n",
    "            initializer_zero(self.linears[-1].bias)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        if self._input_transform is not None:\n",
    "            x = self._input_transform(x)\n",
    "        \n",
    "        for j, linear in enumerate(self.linears[:-1]):\n",
    "            x = (\n",
    "                self.activation[j0](linear(x))\n",
    "                if isinstance(self.activation, list)\n",
    "                else self.activation(linear(x))\n",
    "            )\n",
    "        x = self.linears[-1](x)\n",
    "        if self._output_transform is not None:\n",
    "            x = self._output_transform(inputs, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17191b1-c742-464d-9094-25f1e49f623e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6642, 2)\n",
      "(6642, 1)\n",
      "(246, 2)\n",
      "(246, 1)\n"
     ]
    }
   ],
   "source": [
    "xa_scaler=MinMaxScaler(feature_range=(0,1))\n",
    "xb_scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "train = pd.read_csv(\"C:\\\\Users\\\\ASUS001\\\\Desktop\\\\本科毕设\\\\孙国栋毕设\\\\间隙预测电流_训练集.csv\",encoding='gbk')\n",
    "u_train = train[['Time','Gap']]\n",
    "u_train=xa_scaler.fit_transform(u_train)\n",
    "s_train = train[['Current density']]\n",
    "s_train=xb_scaler.fit_transform(s_train)\n",
    "u_train = np.array(u_train, dtype='float32')\n",
    "s_train = np.array(s_train, dtype='float32')\n",
    "print(u_train.shape)\n",
    "print(s_train.shape)\n",
    "\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\ASUS001\\\\Desktop\\\\本科毕设\\孙国栋毕设\\\\间隙预测电流_测试集.csv\",encoding='gbk')\n",
    "u_test = test[['Time','Gap']]\n",
    "u_test=xa_scaler.transform(u_test)  \n",
    "s_test = test[['Current density']]\n",
    "s_test=xb_scaler.transform(s_test)\n",
    "u_test = np.array(u_test, dtype='float32')\n",
    "s_test = np.array(s_test, dtype='float32')\n",
    "print(u_test.shape)\n",
    "print(s_test.shape)\n",
    "\n",
    "data_train = Tuple(u_train, s_train, u_test, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d441cdb-730f-44ac-8eee-f4709419580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FNN(\n",
    "    [2, 30, 30,30, 30,1],\n",
    "    \"gelu\",\n",
    "    \"Glorot normal\",\n",
    "    regularization=[\"l2\",1e-8]\n",
    ")\n",
    "ModelCheckpoint = dde.callbacks.ModelCheckpoint(filepath='F:\\\\datasets\\\\pulsedDBD\\\\DNN4PulsedDBD\\\\model\\\\test',verbose=1,save_better_only=True,period=100,monitor=\"test loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee51b2-7270-483e-b417-0f14a4cdec06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.642453 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss    Test loss     Test metric   \n",
      "0         [3.41e-01]    [3.41e-01]    [inf]         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\python\\lib\\site-packages\\deepxde\\metrics.py:26: RuntimeWarning: divide by zero encountered in divide\n",
      "  np.linalg.norm(y_true - y_pred, axis=1) / np.linalg.norm(y_true, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: train loss improved from inf to 3.41e-01, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-100.pt ...\n",
      "\n",
      "1000      [1.67e-03]    [1.67e-03]    [inf]         \n",
      "Epoch 1000: train loss improved from 3.41e-01 to 1.67e-03, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-1000.pt ...\n",
      "\n",
      "2000      [3.52e-04]    [3.52e-04]    [inf]         \n",
      "Epoch 2000: train loss improved from 1.67e-03 to 3.52e-04, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-2000.pt ...\n",
      "\n",
      "3000      [2.20e-04]    [2.20e-04]    [inf]         \n",
      "Epoch 3000: train loss improved from 3.52e-04 to 2.20e-04, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-3000.pt ...\n",
      "\n",
      "4000      [1.78e-04]    [1.78e-04]    [inf]         \n",
      "Epoch 4000: train loss improved from 2.20e-04 to 1.78e-04, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-4000.pt ...\n",
      "\n",
      "5000      [1.47e-04]    [1.47e-04]    [inf]         \n",
      "Epoch 5000: train loss improved from 1.78e-04 to 1.47e-04, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-5000.pt ...\n",
      "\n",
      "6000      [1.09e-04]    [1.09e-04]    [inf]         \n",
      "Epoch 6000: train loss improved from 1.47e-04 to 1.09e-04, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-6000.pt ...\n",
      "\n",
      "7000      [4.19e-05]    [4.19e-05]    [inf]         \n",
      "Epoch 7000: train loss improved from 1.09e-04 to 4.19e-05, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-7000.pt ...\n",
      "\n",
      "8000      [2.44e-05]    [2.44e-05]    [inf]         \n",
      "Epoch 8000: train loss improved from 4.19e-05 to 2.44e-05, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-8000.pt ...\n",
      "\n",
      "9000      [2.57e-05]    [2.57e-05]    [inf]         \n",
      "10000     [1.46e-05]    [1.46e-05]    [inf]         \n",
      "Epoch 10000: train loss improved from 2.44e-05 to 1.46e-05, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-10000.pt ...\n",
      "\n",
      "11000     [1.11e-05]    [1.11e-05]    [inf]         \n",
      "Epoch 11000: train loss improved from 1.46e-05 to 1.11e-05, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-11000.pt ...\n",
      "\n",
      "12000     [8.59e-06]    [8.59e-06]    [inf]         \n",
      "Epoch 12000: train loss improved from 1.11e-05 to 8.59e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-12000.pt ...\n",
      "\n",
      "13000     [7.17e-06]    [7.17e-06]    [inf]         \n",
      "Epoch 13000: train loss improved from 8.59e-06 to 7.17e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-13000.pt ...\n",
      "\n",
      "14000     [6.58e-06]    [6.58e-06]    [inf]         \n",
      "Epoch 14000: train loss improved from 7.17e-06 to 6.58e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-14000.pt ...\n",
      "\n",
      "15000     [5.35e-06]    [5.35e-06]    [inf]         \n",
      "Epoch 15000: train loss improved from 6.58e-06 to 5.35e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-15000.pt ...\n",
      "\n",
      "16000     [7.40e-06]    [7.40e-06]    [inf]         \n",
      "17000     [4.46e-06]    [4.46e-06]    [inf]         \n",
      "Epoch 17000: train loss improved from 5.35e-06 to 4.46e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-17000.pt ...\n",
      "\n",
      "18000     [4.15e-06]    [4.15e-06]    [inf]         \n",
      "Epoch 18000: train loss improved from 4.46e-06 to 4.15e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-18000.pt ...\n",
      "\n",
      "19000     [3.89e-06]    [3.89e-06]    [inf]         \n",
      "Epoch 19000: train loss improved from 4.15e-06 to 3.89e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-19000.pt ...\n",
      "\n",
      "20000     [3.67e-06]    [3.67e-06]    [inf]         \n",
      "Epoch 20000: train loss improved from 3.89e-06 to 3.67e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-20000.pt ...\n",
      "\n",
      "21000     [3.48e-06]    [3.48e-06]    [inf]         \n",
      "Epoch 21000: train loss improved from 3.67e-06 to 3.48e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-21000.pt ...\n",
      "\n",
      "22000     [5.36e-06]    [5.36e-06]    [inf]         \n",
      "23000     [3.16e-06]    [3.16e-06]    [inf]         \n",
      "Epoch 23000: train loss improved from 3.48e-06 to 3.16e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-23000.pt ...\n",
      "\n",
      "24000     [3.02e-06]    [3.02e-06]    [inf]         \n",
      "Epoch 24000: train loss improved from 3.16e-06 to 3.02e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-24000.pt ...\n",
      "\n",
      "25000     [3.23e-06]    [3.23e-06]    [inf]         \n",
      "26000     [2.82e-06]    [2.82e-06]    [inf]         \n",
      "Epoch 26000: train loss improved from 3.02e-06 to 2.82e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-26000.pt ...\n",
      "\n",
      "27000     [2.74e-06]    [2.74e-06]    [inf]         \n",
      "Epoch 27000: train loss improved from 2.82e-06 to 2.74e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-27000.pt ...\n",
      "\n",
      "28000     [2.59e-06]    [2.59e-06]    [inf]         \n",
      "Epoch 28000: train loss improved from 2.74e-06 to 2.59e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-28000.pt ...\n",
      "\n",
      "29000     [2.64e-06]    [2.64e-06]    [inf]         \n",
      "30000     [2.41e-06]    [2.41e-06]    [inf]         \n",
      "Epoch 30000: train loss improved from 2.59e-06 to 2.41e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-30000.pt ...\n",
      "\n",
      "31000     [2.34e-06]    [2.34e-06]    [inf]         \n",
      "Epoch 31000: train loss improved from 2.41e-06 to 2.34e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-31000.pt ...\n",
      "\n",
      "32000     [2.63e-06]    [2.63e-06]    [inf]         \n",
      "33000     [2.19e-06]    [2.19e-06]    [inf]         \n",
      "Epoch 33000: train loss improved from 2.34e-06 to 2.19e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-33000.pt ...\n",
      "\n",
      "34000     [6.00e-06]    [6.00e-06]    [inf]         \n",
      "35000     [2.21e-06]    [2.21e-06]    [inf]         \n",
      "36000     [1.98e-06]    [1.98e-06]    [inf]         \n",
      "Epoch 36000: train loss improved from 2.19e-06 to 1.98e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-36000.pt ...\n",
      "\n",
      "37000     [2.07e-06]    [2.07e-06]    [inf]         \n",
      "38000     [1.84e-06]    [1.84e-06]    [inf]         \n",
      "Epoch 38000: train loss improved from 1.98e-06 to 1.84e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-38000.pt ...\n",
      "\n",
      "39000     [2.17e-06]    [2.17e-06]    [inf]         \n",
      "40000     [1.70e-06]    [1.70e-06]    [inf]         \n",
      "Epoch 40000: train loss improved from 1.84e-06 to 1.70e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-40000.pt ...\n",
      "\n",
      "41000     [1.64e-06]    [1.64e-06]    [inf]         \n",
      "Epoch 41000: train loss improved from 1.70e-06 to 1.64e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-41000.pt ...\n",
      "\n",
      "42000     [1.62e-06]    [1.62e-06]    [inf]         \n",
      "Epoch 42000: train loss improved from 1.64e-06 to 1.62e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-42000.pt ...\n",
      "\n",
      "43000     [1.50e-06]    [1.50e-06]    [inf]         \n",
      "Epoch 43000: train loss improved from 1.62e-06 to 1.50e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-43000.pt ...\n",
      "\n",
      "44000     [1.52e-06]    [1.52e-06]    [inf]         \n",
      "45000     [1.38e-06]    [1.38e-06]    [inf]         \n",
      "Epoch 45000: train loss improved from 1.50e-06 to 1.38e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-45000.pt ...\n",
      "\n",
      "46000     [4.54e-06]    [4.54e-06]    [inf]         \n",
      "47000     [1.28e-06]    [1.28e-06]    [inf]         \n",
      "Epoch 47000: train loss improved from 1.38e-06 to 1.28e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-47000.pt ...\n",
      "\n",
      "48000     [1.16e-06]    [1.16e-06]    [inf]         \n",
      "Epoch 48000: train loss improved from 1.28e-06 to 1.16e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-48000.pt ...\n",
      "\n",
      "49000     [2.56e-06]    [2.56e-06]    [inf]         \n",
      "50000     [1.01e-06]    [1.01e-06]    [inf]         \n",
      "Epoch 50000: train loss improved from 1.16e-06 to 1.01e-06, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-50000.pt ...\n",
      "\n",
      "51000     [9.66e-07]    [9.66e-07]    [inf]         \n",
      "Epoch 51000: train loss improved from 1.01e-06 to 9.66e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-51000.pt ...\n",
      "\n",
      "52000     [9.07e-07]    [9.07e-07]    [inf]         \n",
      "Epoch 52000: train loss improved from 9.66e-07 to 9.07e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-52000.pt ...\n",
      "\n",
      "53000     [1.63e-06]    [1.63e-06]    [inf]         \n",
      "54000     [1.47e-06]    [1.47e-06]    [inf]         \n",
      "55000     [7.67e-07]    [7.67e-07]    [inf]         \n",
      "Epoch 55000: train loss improved from 9.07e-07 to 7.67e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-55000.pt ...\n",
      "\n",
      "56000     [7.37e-07]    [7.37e-07]    [inf]         \n",
      "Epoch 56000: train loss improved from 7.67e-07 to 7.37e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-56000.pt ...\n",
      "\n",
      "57000     [6.95e-07]    [6.95e-07]    [inf]         \n",
      "Epoch 57000: train loss improved from 7.37e-07 to 6.95e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-57000.pt ...\n",
      "\n",
      "58000     [6.56e-07]    [6.56e-07]    [inf]         \n",
      "Epoch 58000: train loss improved from 6.95e-07 to 6.56e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-58000.pt ...\n",
      "\n",
      "59000     [6.24e-07]    [6.24e-07]    [inf]         \n",
      "Epoch 59000: train loss improved from 6.56e-07 to 6.24e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-59000.pt ...\n",
      "\n",
      "60000     [1.51e-06]    [1.51e-06]    [inf]         \n",
      "61000     [5.66e-07]    [5.66e-07]    [inf]         \n",
      "Epoch 61000: train loss improved from 6.24e-07 to 5.66e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-61000.pt ...\n",
      "\n",
      "62000     [5.37e-07]    [5.37e-07]    [inf]         \n",
      "Epoch 62000: train loss improved from 5.66e-07 to 5.37e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-62000.pt ...\n",
      "\n",
      "63000     [5.15e-07]    [5.15e-07]    [inf]         \n",
      "Epoch 63000: train loss improved from 5.37e-07 to 5.15e-07, saving model to F:\\datasets\\pulsedDBD\\DNN4PulsedDBD\\model\\test-63000.pt ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = dde.Model(data_train, net)\n",
    "model.compile(\"adamw\", lr=0.01,decay=[\"step\",50000,0.5], metrics=[\"mean l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=50000,batch_size=None,callbacks=[ModelCheckpoint])\n",
    "dde.utils.plot_loss_history(losshistory,fname='F:\\\\datasets\\\\sinDBD-frequency\\\\MaxNe2V\\\\losshistory.png') #fname是损失下降图片的保存地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b224e432-6f29-49cc-9784-935fc7ef8f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000258 s\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FNN:\n\tsize mismatch for linears.0.weight: copying a param with shape torch.Size([30, 1]) from checkpoint, the shape in current model is torch.Size([30, 2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m dde\u001b[38;5;241m.\u001b[39mModel(data_train, net)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madamw\u001b[39m\u001b[38;5;124m\"\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m,decay\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m500000\u001b[39m,\u001b[38;5;241m0.5\u001b[39m], metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean l2 relative error\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpulsedDBD\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDNN4PulsedDBD\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtest-12000.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\anaconda3\\envs\\python\\lib\\site-packages\\deepxde\\model.py:1091\u001b[0m, in \u001b[0;36mModel.restore\u001b[1;34m(self, save_path, device, verbose)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m         checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(save_path)\n\u001b[1;32m-> 1091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mF:\\anaconda3\\envs\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FNN:\n\tsize mismatch for linears.0.weight: copying a param with shape torch.Size([30, 1]) from checkpoint, the shape in current model is torch.Size([30, 2])."
     ]
    }
   ],
   "source": [
    "model = dde.Model(data_train, net)\n",
    "model.compile(\"adamw\", lr=0.0005,decay=[\"step\",500000,0.5], metrics=[\"mean l2 relative error\"])\n",
    "model.restore('F:\\\\datasets\\\\pulsedDBD\\\\DNN4PulsedDBD\\\\model\\\\test-12000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67951db3-a88b-4810-8343-9b0b0c9d2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(u_test)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.plot(xb_scaler.inverse_transform(s_test), label='True Output', linestyle='--')\n",
    "plt.plot(xb_scaler.inverse_transform(y_pred), label='Predicted Output', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Current density')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python]",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
